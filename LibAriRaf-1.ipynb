{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL FUNCTIONS AND CODE BITS DEFINED DURING COURSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ExternalFunctions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1cb676e74190>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/AppStat/AppStat2019_local/External_Functions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mExternalFunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChi2Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mExternalFunctions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnice_string_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_text_to_ax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ExternalFunctions'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "from iminuit import Minuit \n",
    "from scipy.stats import binom, poisson\n",
    "from scipy.stats import chi2\n",
    "\n",
    "sys.path.append('/AppStat/AppStat2019_local/External_Functions')\n",
    "from ExternalFunctions import Chi2Regression\n",
    "from ExternalFunctions import nice_string_output, add_text_to_ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_mean(data,weights):\n",
    "    mean = 0\n",
    "    weighted_sum = 0\n",
    "    \n",
    "    if sum(weights) == 1:\n",
    "        for i in range(len(data)):\n",
    "            mean = mean + data[i]*weights[i]\n",
    "        mean = mean/len(weights)\n",
    "    \n",
    "    else:\n",
    "        for i in range(len(data)):\n",
    "            mean = mean + data[i]*weights[i]\n",
    "            weighted_sum = weighted_sum + weights[i]\n",
    "        mean = mean/weighted_sum\n",
    "\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_std(data, weights, mean):\n",
    "    std = 0\n",
    "    weighted_sum = 0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        std = std + weights[i]*(data[i]-mean)**2\n",
    "        weighted_sum = weighted_sum + weights[i]\n",
    "    std = std/(weighted_sum)\n",
    "    std = np.sqrt(std)\n",
    "\n",
    "    return std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_gaussian_norm(x, sigma, mu, N) :\n",
    "    result = N/(np.sqrt(2*np.pi))*np.exp(-0.5*((x-mu)/sigma)**2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_gaussian(x, sigma, mu):\n",
    "    result = 1/(sigma*np.sqrt(2*np.pi))*np.exp(-0.5*((x-mu)/sigma)**2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CDF - Gaussian integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaus_between_a_b(a,b):\n",
    "    p_value = 2*(norm.cdf(a)-norm.cdf(b))\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binom_func(n,p,N):\n",
    "    P = math.factorial(n)/(math.factorial(N)*math.factorial(n-N)) * p**N * (1-p)**(n-N)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial - probability of getting P and over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_of_above_P(P,n,p):\n",
    "    prob_to_P = 0\n",
    "    for N_sum in range(0,P):                              #If you don't play you can't win\n",
    "        prob_to_P = prob_to_P + binom_func(n,p,N_sum)\n",
    "\n",
    "    prob_P_plus_1_and_over = 1-prob_to_P\n",
    "    return prob_P_plus_1_and_over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poissonian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Poissonian_func(k,Lambda):\n",
    "    P_pois = Lambda**k * np.exp(-Lambda)/(math.factorial(k))\n",
    "    return P_pois"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_calculations(observed, expected, errors):\n",
    "    chi2_calc = 0\n",
    "    \n",
    "    if type(expected) != list or type(expected) != np.array: \n",
    "        expected = expected*np.ones(len(observed))\n",
    "    if type(errors) != list or type(errors) != np.array: \n",
    "        errors = errors*np.ones(len(observed))\n",
    "    \n",
    "    chi2_list = []\n",
    "    for i in range (0,len(observed)):\n",
    "        if errors[i] != 0:\n",
    "            chi2_calc = chi2_calc + (observed[i]-expected[i])**2/errors[i]**2\n",
    "            \n",
    "            chi2_list.append((observed[i]-expected[i])**2/errors[i]**2)\n",
    "    return chi2_calc, chi2_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple (here 3) Gaussians on slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_gpol0(x,a,mu1,sigma1,b,mu2,sigma2,c,mu3,sigma3, cst,slope) :\n",
    "    norm1 = binwidth_gauss * a / np.sqrt(2.0*np.pi) / sigma1\n",
    "    norm2 = binwidth_gauss * b / np.sqrt(2.0*np.pi) / sigma2\n",
    "    norm3 = binwidth_gauss * c / np.sqrt(2.0*np.pi) / sigma3\n",
    "    z1 = (x-mu1)/sigma1\n",
    "    z2 = (x-mu2)/sigma2\n",
    "    z3 = (x-mu3)/sigma3\n",
    "   \n",
    "    return norm1 * np.exp(-0.5*z1*z1) + cst + norm2 * np.exp(-0.5*z2*z2) + norm3 * np.exp(-0.5*z3*z3) + slope*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation of 2 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error propagation\n",
    "def dfdx(param1,param2,param3):\n",
    "    \n",
    "    derivative = param1 + param2 + param3 #Find your derivative!!!\n",
    "    \n",
    "    return derivative\n",
    "\n",
    "def dfdy(param1,param2,param3):\n",
    "    \n",
    "    derivative = param1 + param2 + param3 #Find your derivative!!!\n",
    "    \n",
    "    return derivative\n",
    "\n",
    "def sig_tot_corr(dfdx,x_err,dfdy,y_err,rho):\n",
    "    V = x_err*y_err*rho\n",
    "    Sig_tot_corr = np.sqrt((dfdx(param1,param2,param3)**2)*x_err**2 + (dfdy(param1,param2,param3)**2)*y_err**2 + \n",
    "                          2*dfdx(param1,param2,param3)*(dfdy(param1,param2,param3))*V)\n",
    "    return Sig_tot_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance and correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_corr(A,B):\n",
    "    meanA = np.mean(A)\n",
    "    meanB = np.mean(B)\n",
    "    stdA = np.std(A)\n",
    "    stdB = np.std(B)\n",
    "    Covariance = np.mean((A-meanA)*(B-meanB))\n",
    "    CorrCoeff = Covariance/(stdA*stdB)\n",
    "    return Covariance, CorrCoeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-CURVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve from two histograms (hist1 is signal, hist2 is background):\n",
    "def calc_ROC(hist1, hist2) :\n",
    "\n",
    "    # First we extract the entries (y values) and the edges of the histograms\n",
    "    y_sig, x_sig_edges, _ = hist1 \n",
    "    y_bkg, x_bkg_edges, _ = hist2\n",
    "    \n",
    "    # Check that the two histograms have the same x edges:\n",
    "    if np.array_equal(x_sig_edges, x_bkg_edges) :\n",
    "        \n",
    "        # Extract the center positions (x values) of the bins (both signal or background works - equal binning)\n",
    "        x_centers = 0.5*(x_sig_edges[1:] + x_sig_edges[:-1])\n",
    "        \n",
    "        # Calculate the integral (sum) of the signal and background:\n",
    "        integral_sig = y_sig.sum()\n",
    "        integral_bkg = y_bkg.sum()\n",
    "    \n",
    "        # Initialize empty arrays for the True Positive Rate (TPR) and the False Positive Rate (FPR):\n",
    "        TPR = np.zeros_like(y_sig) # True positive rate (sensitivity)\n",
    "        FPR = np.zeros_like(y_sig) # False positive rate ()\n",
    "        \n",
    "        # Loop over all bins (x_centers) of the histograms and calculate TN, FP, FN, TP, FPR, and TPR for each bin:\n",
    "        for i, x in enumerate(x_centers): \n",
    "            \n",
    "            # The cut mask\n",
    "            cut = (x_centers < x)\n",
    "            \n",
    "            # True positive\n",
    "            TP = np.sum(y_sig[~cut]) / integral_sig    # True positives\n",
    "            FN = np.sum(y_sig[cut]) / integral_sig     # False negatives\n",
    "            TPR[i] = TP / (TP + FN)                    # True positive rate\n",
    "            \n",
    "            # True negative\n",
    "            TN = np.sum(y_bkg[cut]) / integral_bkg      # True negatives (background)\n",
    "            FP = np.sum(y_bkg[~cut]) / integral_bkg     # False positives\n",
    "            FPR[i] = FP / (FP + TN)                     # False positive rate            \n",
    "            \n",
    "        return FPR, TPR\n",
    "    \n",
    "    else:\n",
    "        AssertionError(\"Signal and Background histograms have different bins and ranges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher -discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fisher_disc(N, Hypo, *args):\n",
    "\n",
    "    assert N == len(args) , f\"*args has more arguments (len(args) = {len(args)}) as desired N = {len(N)}\"\n",
    "    \n",
    "    marker_list = []\n",
    "    for marker in args:\n",
    "       \n",
    "        # get events for each hpothesis\n",
    "        h_0 = [x for i,x in enumerate(marker) if Hypo[i] == 0]\n",
    "        h_1 = [x for i,x in enumerate(marker) if Hypo[i] == 1]\n",
    "        \n",
    "        marker_list = np.append(marker_list,{'0':h_0,'1':h_1})\n",
    "\n",
    "    # get covariance matrix for null hypo.\n",
    "    V_0 = np.array([cov_corr(x[0]['0'],x[1]['0'])[0] for x in  itertools.product(marker_list, marker_list)], \n",
    "                   dtype = np.float64)\n",
    "    V_0 = np.reshape(V_0, (len(marker_list),len(marker_list)))\n",
    "            \n",
    "    # get covariance matrix for alternativ hypo.\n",
    "    V_1 = np.array([cov_corr(x[0]['1'],x[1]['1'])[0] for x in  itertools.product(marker_list, marker_list)], \n",
    "                   dtype = np.float64)\n",
    "    V_1 = np.reshape(V_1, (len(marker_list),len(marker_list)))\n",
    "\n",
    "\n",
    "    mean_0 = [np.mean(x['0']) for x in marker_list]\n",
    "    mean_1 = [np.mean(x['1']) for x in marker_list]\n",
    "    \n",
    "\n",
    "\n",
    "    W = V_0 + V_1\n",
    "    alpha = np.dot(np.linalg.inv(W),(np.array(mean_0)-np.array(mean_1)))\n",
    "    \n",
    "    \n",
    "    return W, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Nice Plotting Routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_errorbar(H, plt_opt = True):\n",
    "    # get binwidth\n",
    "    dbin = np.abs(H[1][0]-H[1][1])\n",
    "    \n",
    "    # get midpoints of each bin \n",
    "    mid_bin = [np.abs(H[1][0]+H[1][1])/2 + i*dbin for i in range(len(H[1])-1)]\n",
    "    \n",
    "    # get error \n",
    "    error_bin = np.sqrt(H[0])\n",
    "    \n",
    "    if plt_opt == True:\n",
    "        fig, ax = plt.subplots()\n",
    "        # plot errobar\n",
    "        ax.errorbar(mid_bin,H[0],yerr=error_bin, linestyle = \" \", marker='o', mfc='coral',\n",
    "         mec='coral', ms=3, mew=3)\n",
    "        # plot step-func to show the underlying histogram\n",
    "        ax.step(H[1][1::],H[0],alpha =0.6)\n",
    "    \n",
    "    # return (mid-point of bin, bin count, errors per bin) and min(bin count) \n",
    "    # to check for possible low count statistic\n",
    "    return (mid_bin, H[0], error_bin), min(H[0]), ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE SNIPPETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of minuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "chi2_pdf = Chi2Regression(func_pdf, test_x, count, np.sqrt(count))\n",
    "# func_pdf is function, test_x is from Monte Carlo, count is the count in histogram, np.sqrt(count) is error of hist\n",
    "\n",
    "minuit_pdf = Minuit(chi2_pdf, pedantic=False, A=2) \n",
    "# Stating wished function with guesses on paramters, here A=2. To fix parameters write fix_A = True\n",
    "\n",
    "minuit_pdf.migrad();      \n",
    "# Perform the actual fit\n",
    "\n",
    "\n",
    "Ndof = len(test_x) - N_param           \n",
    "# N_param is number of parameters in fit, here N_param = 1\n",
    "\n",
    "Prob = scipy.stats.chi2.sf(minuit_pdf.fval, Ndof)\n",
    "# Getting prbability of chi2 fitting\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "np.random.seed(42)\n",
    "# In order to have same outpur always\n",
    "\n",
    "ran_dist = np.random.rand(400)*2\n",
    "# Creating 400 random variables in range [0;2]\n",
    "\n",
    "BOX = C/2*ran_dist \n",
    "### WHY DID WE DIVIDE BY HALF?\n",
    "\n",
    "\n",
    "ran_dist_func = C*(1-np.exp(-a*ran_dist))\n",
    "# Creating numbers according to the wanted distribution\n",
    "\n",
    "fig4, ax_4 = plt.subplots(nrows=1, ncols=2, figsize=(15, 5),sharex=True)\n",
    "\n",
    "SAVE = []\n",
    "\n",
    "while len(SAVE) < 500:\n",
    "    ax_4[0].cla()\n",
    "    SAVE = []\n",
    "    ran_dist = np.random.rand(len(ran_dist)+100)*2\n",
    "    # Creating enough numbers to satisfy problem\n",
    "    \n",
    "    for i in ran_dist:\n",
    "        u = np.random.rand(1)\n",
    "        if C*u <= C*(1-np.exp(-a*i)):\n",
    "            ax_4[0].plot(i,C*u,marker ='o', color = 'red')\n",
    "            SAVE.append(i)\n",
    "        else:\n",
    "            ax_4[0].plot(i,C*u,marker ='o', color = 'blue')\n",
    "\n",
    "SAVE = np.array(SAVE[0:500])\n",
    "# Making sure we have the stated number\n",
    "\n",
    "HIST = ax_4[1].hist(SAVE,30);\n",
    "ax_4[1].cla()\n",
    "# We do not want to plot the histogram itself\n",
    "\n",
    "ax_4[1].plot(np.sort(SAVE),[len(HIST[0])*C*(1-np.exp(-a*i)) for i in np.sort(SAVE)],marker=' ',linestyle='-')\n",
    "\n",
    "count = HIST[0]\n",
    "\n",
    "hist_std = np.sqrt(count)\n",
    "\n",
    "test_x = np.linspace(HIST[1][0]+np.diff(HIST[1])[0]/2,HIST[1][-1],len(HIST[0]))\n",
    "ax_4[1].errorbar(test_x,count,hist_std,linestyle =' ', marker ='o');\n",
    "ax_4[1].set_ylabel('counts')\n",
    "ax_4[1].set_xlabel('x')\n",
    "\n",
    "fig4.savefig('MonteCarlo.png')\n",
    "\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing data in large histogram to smaller pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data = np.array(x)\n",
    "print(\"The number of entries in the file was: \", len(x))\n",
    "\n",
    "fig_gamma, ax_gamma = plt.subplots()\n",
    "H = ax_gamma.hist(data,1000);\n",
    "\n",
    "\n",
    "window_low = 105\n",
    "window_up = 170\n",
    "# Choose which entries you want to slice to\n",
    "\n",
    "ax_gamma.set_xlim(window_low, window_up)\n",
    "\n",
    "\n",
    "x_data = [x for x in H[1] if x>window_low and x<window_up]\n",
    "print(len(x_data))\n",
    "\n",
    "y_data = [H[0][i] for i in range(len(H[1])) if H[1][i]>window_low and H[1][i]<window_up]\n",
    "print(len(y_data))\n",
    "\n",
    "# slice out data in window and make sure the code did it by printing\n",
    "\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
